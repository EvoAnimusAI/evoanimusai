# core/engine.py
# -*- coding: utf-8 -*-
"""
EvoAIEngine ‚Äî N√∫cleo heur√≠stico de EvoAnimusAI
-----------------------------------------------
- Motor de decisiones heur√≠sticas basado en reglas y prioridad adaptativa
- Compatible con aprendizaje simb√≥lico, control de entrop√≠a y supervisi√≥n metacognitiva
- Nivel: Militar / Gubernamental / Ultra
"""

import logging
import random
import re
from typing import Any, Dict, List

from utils.default_rules import get_default_rules
from symbolic_ai.symbolic_learning_engine import SymbolicLearningEngine
from symbolic_ai.symbolic_entropy_controller import SymbolicEntropyController
from symbolic_ai.symbolic_rule_engine import SymbolicRuleEngine
from metacognition.metacognitive_supervisor import MetacognitiveSupervisor  # ‚úÖ Integrado

logger = logging.getLogger("EvoAI.Engine")
logger.setLevel(logging.INFO)

def parse_symbolic_rule(rule_str: str) -> Dict[str, Any]:
    match = re.match(r"‚ü¶(?P<rol>\w+):(?P<valor>\w+)‚üß ‚áí (?P<accion>\w+) :: (?P<condicion>.+)", rule_str)
    if not match:
        raise ValueError(f"[‚ùå ERROR] Formato inv√°lido de regla simb√≥lica: {rule_str}")
    return {
        "role": match.group("rol"),
        "value": match.group("valor"),
        "action": match.group("accion"),
        "condition": match.group("condicion"),
        "priority": 1.0
    }

class RuleEngineAdapter:
    def __init__(self, rules: List[Dict[str, Any]]) -> None:
        self.rules = [r for r in rules if isinstance(r, dict)]
        print(f"[üîß RuleEngineAdapter] Inicializado con {len(self.rules)} reglas v√°lidas.")

    def evaluate(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        print(f"[üì• EVALUATE] Contexto recibido: {context}")
        results = []
        for r in self.rules:
            try:
                cond = r.get("condition", "True")
                if eval(cond, {}, context):  # ‚ö†Ô∏è Solo en entornos cerrados
                    results.append(r)
            except Exception as e:
                print(f"[‚ö†Ô∏è ERROR] Evaluaci√≥n fallida para regla {r}: {e}")
        sorted_results = sorted(results, key=lambda r: r.get("priority", 1.0), reverse=True)
        print(f"[üì§ RESULTADOS] Evaluaci√≥n heur√≠stica: {sorted_results}")
        return sorted_results

    def add_rule(self, rule: Any) -> None:
        print(f"[‚ûï ADD_RULE] Intentando agregar: {rule}")
        if isinstance(rule, str):
            try:
                rule = parse_symbolic_rule(rule)
            except ValueError as e:
                print(f"[‚ùå ADD_RULE ERROR] {e}")
                return
        elif not isinstance(rule, dict):
            print(f"[‚ùå ADD_RULE ERROR] Tipo no soportado: {type(rule)}")
            return
        self.rules.append(rule)
        print(f"[‚úÖ ADD_RULE] Regla agregada: {rule}")

    def remove_rule(self, rule: Any) -> None:
        print(f"[‚ûñ REMOVE_RULE] Intentando eliminar: {rule}")
        if rule in self.rules:
            self.rules.remove(rule)
            print("[‚úÖ REMOVE_RULE] Regla eliminada.")
        else:
            print("[‚ö†Ô∏è REMOVE_RULE] Regla no encontrada.")

class EvoAIEngine:
    def __init__(self) -> None:
        print("[üîß INIT] Iniciando EvoAnimusAI...")
        self.rules = get_default_rules()
        self.adapter = RuleEngineAdapter(self.rules)
        self.learning_engine = SymbolicLearningEngine(self.adapter)
        self.entropy_controller = SymbolicEntropyController(entropy=0.0)
        self.metacog = MetacognitiveSupervisor(error_threshold=0.8, stagnation_limit=20)  # ‚úÖ Militar
        print(f"[INFO] [INIT] Motor heur√≠stico inicializado con {len(self.rules)} reglas.")

    def decide(self, context: Dict[str, Any]) -> Dict[str, Any]:
        print(f"\nüîÑ [CICLO #{context.get('cycle', '?')}] ------------------------------")
        print(f"[üß† DECIDE] Contexto heur√≠stico: {context}")

        entropy = context.get("entropy", 0.0)
        self.entropy_controller.update_entropy(entropy)

        try:
            stop, reasons = self.metacog.should_stop(context)
            if stop:
                print(f"[üß† METACOG STOP] Detenido por supervisor metacognitivo. Razones: {reasons}")
                return {"action": "halt"}
        except Exception as e:
            print(f"[‚ö†Ô∏è METACOG ERROR] Error en evaluaci√≥n metacognitiva: {e}")

        if self.entropy_controller.requires_halt():
            print("[üö® HALT] Entrop√≠a excedida. Decisi√≥n: HALT")
            return {"action": "halt"}

        evaluated = self.adapter.evaluate(context)

        if evaluated:
            selected = evaluated[0]
            print(f"[‚úÖ SELECTED] Acci√≥n seleccionada: {selected.get('action')}")
            return {"action": selected.get("action", "wait")}
        else:
            print("[‚ö†Ô∏è DEFAULT ACTION] Acci√≥n: wait")
            return {"action": "wait"}

    def learn(self, context: Dict[str, Any], action: str, reward: float) -> None:
        print(f"[üìö LEARN] Observaci√≥n: {context}, Acci√≥n: {action}, Recompensa: {reward}")
        try:
            self.learning_engine.update_rule(action, reward)
        except Exception as e:
            print(f"[‚ùå ERROR] Fallo en aprendizaje simb√≥lico: {e}")

        try:
            self.entropy_controller.update_entropy_change(reward)
        except AttributeError as e:
            print(f"[‚ùå ERROR] Faltante m√©todo 'update_entropy_change': {e}")
        except Exception as e:
            print(f"[‚ùå ERROR] Fallo en controlador de entrop√≠a: {e}")
